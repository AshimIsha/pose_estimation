{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:12.945026Z",
     "start_time": "2024-04-24T23:15:07.082577Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:12.960855Z",
     "start_time": "2024-04-24T23:15:12.946892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, UpSampling2D, BatchNormalization"
   ],
   "id": "ce44801bf4d6eaa7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.005734Z",
     "start_time": "2024-04-24T23:15:12.962849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('train_frames.csv')\n",
    "test_df = pd.read_csv('test_frames.csv')\n",
    "train_df"
   ],
   "id": "abad51b1a7394069",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             video         frame_path          label\n",
       "0      GcluCxjiSjI     frames/0_0.jpg    tap dancing\n",
       "1      GcluCxjiSjI     frames/0_1.jpg    tap dancing\n",
       "2      GcluCxjiSjI     frames/0_2.jpg    tap dancing\n",
       "3      GcluCxjiSjI     frames/0_3.jpg    tap dancing\n",
       "4      GcluCxjiSjI     frames/0_4.jpg    tap dancing\n",
       "...            ...                ...            ...\n",
       "12694  LT-e_wj6d9w  frames/617_16.jpg  tango dancing\n",
       "12695  LT-e_wj6d9w  frames/617_17.jpg  tango dancing\n",
       "12696  LT-e_wj6d9w  frames/617_18.jpg  tango dancing\n",
       "12697  LT-e_wj6d9w  frames/617_19.jpg  tango dancing\n",
       "12698  LT-e_wj6d9w  frames/617_20.jpg  tango dancing\n",
       "\n",
       "[12699 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GcluCxjiSjI</td>\n",
       "      <td>frames/0_0.jpg</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GcluCxjiSjI</td>\n",
       "      <td>frames/0_1.jpg</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GcluCxjiSjI</td>\n",
       "      <td>frames/0_2.jpg</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GcluCxjiSjI</td>\n",
       "      <td>frames/0_3.jpg</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GcluCxjiSjI</td>\n",
       "      <td>frames/0_4.jpg</td>\n",
       "      <td>tap dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12694</th>\n",
       "      <td>LT-e_wj6d9w</td>\n",
       "      <td>frames/617_16.jpg</td>\n",
       "      <td>tango dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12695</th>\n",
       "      <td>LT-e_wj6d9w</td>\n",
       "      <td>frames/617_17.jpg</td>\n",
       "      <td>tango dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>LT-e_wj6d9w</td>\n",
       "      <td>frames/617_18.jpg</td>\n",
       "      <td>tango dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12697</th>\n",
       "      <td>LT-e_wj6d9w</td>\n",
       "      <td>frames/617_19.jpg</td>\n",
       "      <td>tango dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12698</th>\n",
       "      <td>LT-e_wj6d9w</td>\n",
       "      <td>frames/617_20.jpg</td>\n",
       "      <td>tango dancing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12699 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_df",
   "id": "4fd57f52b2b13636"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.021692Z",
     "start_time": "2024-04-24T23:15:13.006750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_train = train_df[\"label\"]\n",
    "x_train = train_df.drop(labels = [\"label\", \"video\"], axis = 1)\n",
    "\n",
    "y_test = test_df[\"label\"]\n",
    "x_test = test_df.drop(labels = [\"label\", \"video\"], axis = 1)"
   ],
   "id": "10f16995f0f20e4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.037649Z",
     "start_time": "2024-04-24T23:15:13.023687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_train_to_int = {label_name: i for i, label_name in enumerate(set(train_df['label']))}\n",
    "label_test_to_int = {label_name: i for i, label_name in enumerate(set(test_df['label']))}"
   ],
   "id": "8318aa7dd9c2b613",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.053639Z",
     "start_time": "2024-04-24T23:15:13.039651Z"
    }
   },
   "cell_type": "code",
   "source": "label_train_to_int",
   "id": "d806ae10fe752006",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salsa dancing': 0,\n",
       " 'mosh pit dancing': 1,\n",
       " 'square dancing': 2,\n",
       " 'dancing charleston': 3,\n",
       " 'dancing gangnam style': 4,\n",
       " 'tango dancing': 5,\n",
       " 'dancing macarena': 6,\n",
       " 'tap dancing': 7,\n",
       " 'country line dancing': 8,\n",
       " 'swing dancing': 9,\n",
       " 'breakdancing': 10,\n",
       " 'belly dancing': 11,\n",
       " 'jumpstyle dancing': 12,\n",
       " 'robot dancing': 13,\n",
       " 'dancing ballet': 14}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "86f78cb71223c04f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "label_test_to_int",
   "id": "b7ce9f20ea28cfa8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.068567Z",
     "start_time": "2024-04-24T23:15:13.055600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_labels = [label_to_int[label_name] for label_name in train_classes]\n",
    "# test_labels = [label_to_int[label_name] for label_name in test_classes]"
   ],
   "id": "43299d04e9a4da7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.084523Z",
     "start_time": "2024-04-24T23:15:13.069565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels = to_categorical(label_train_to_int, num_classes=15)\n",
    "train_labels = train_labels.astype('float32')\n",
    "test_labels = to_categorical(label_test_to_int, num_classes=15)\n",
    "test_labels = test_labels.astype('float32')\n"
   ],
   "id": "b959fddc172b2bf4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.099519Z",
     "start_time": "2024-04-24T23:15:13.085522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_n_preprocess(frame_path, label):\n",
    "    image = tf.io.read_file(frame_path)\n",
    "    image = tf.image.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [32,32])\n",
    "    image = preprocess_input(image)\n",
    "    image = image / 225\n",
    "\n",
    "    return image, label"
   ],
   "id": "7a0edf4ce64645b5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.115468Z",
     "start_time": "2024-04-24T23:15:13.100482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def lnp_all_images(frame_path):\n",
    "#     images = [load_n_preprocess(frame_path) for frame_path in frames_df['frame_path']]\n",
    "#     return tf.stack(images)"
   ],
   "id": "edb9b23d2d8f5f13",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.194231Z",
     "start_time": "2024-04-24T23:15:13.149350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_frames_tensor = tf.convert_to_tensor(x_train)\n",
    "train_labels_tensor = tf.convert_to_tensor(train_labels)\n",
    "\n",
    "test_frames_tensor = tf.convert_to_tensor(x_test)\n",
    "test_labels_tensor = tf.convert_to_tensor(test_labels)"
   ],
   "id": "37993d15adbd1a49",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.210188Z",
     "start_time": "2024-04-24T23:15:13.197223Z"
    }
   },
   "cell_type": "code",
   "source": "train_frames_tensor",
   "id": "bdfe841a46269640",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8889,), dtype=string, numpy=\n",
       "array([b'frames/19_9.jpg', b'frames/500_9.jpg', b'frames/359_15.jpg', ...,\n",
       "       b'frames/129_6.jpg', b'frames/173_10.jpg', b'frames/378_3.jpg'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.319894Z",
     "start_time": "2024-04-24T23:15:13.211186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_frames_tensor, train_labels_tensor))\n",
    "train_dataset = train_dataset.map(load_n_preprocess)\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset)).batch(64)"
   ],
   "id": "7d488f6fd88a26da",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.349818Z",
     "start_time": "2024-04-24T23:15:13.320892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_frames_tensor, test_labels_tensor))\n",
    "test_dataset = test_dataset.map(load_n_preprocess)\n",
    "test_dataset = test_dataset.shuffle(len(test_dataset)).batch(64)\n"
   ],
   "id": "6d887cef35e6b8c8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:13.380799Z",
     "start_time": "2024-04-24T23:15:13.350812Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset",
   "id": "6acbae43dbf39d22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.646399Z",
     "start_time": "2024-04-24T23:15:13.381729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "# base_model.trainable = False\n",
    "# \n",
    "# model = tf.keras.Sequential([\n",
    "#     base_model,\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(15, activation='softmax')\n",
    "# ])\n",
    "model = None\n",
    "model = Sequential()\n",
    "model.add(UpSampling2D())\n",
    "model.add(UpSampling2D())\n",
    "model.add(UpSampling2D())\n",
    "\n",
    "inc_model = InceptionV3(include_top = False, weights = None, pooling = 'max', classes = 15)\n",
    "for layer in inc_model.layers:\n",
    "    layer.trainable = True\n",
    "            \n",
    "model.add(inc_model)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(15, activation = 'softmax'))"
   ],
   "id": "d907869a253e5229",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.662336Z",
     "start_time": "2024-04-24T23:15:14.647343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NGL(tf.keras.losses.Loss):\n",
    "    def __init__(\n",
    "    \tself, \n",
    "    \tscaling=False,\n",
    "    \tname=\"ngl_loss\"):\n",
    "        super().__init__(name=name)\n",
    "        self.name = name\n",
    "        self.scaling = scaling\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        if self.scaling == True:\n",
    "\t \t        y_pred = tf.math.sigmoid(y_pred)\n",
    "        part_1 = tf.math.exp(2.4092 - y_pred - y_pred*y_true)\n",
    "        part_2 = tf.math.cos(tf.math.cos(tf.math.sin(y_pred)))\n",
    "        elements = part_1 - part_2\n",
    "        loss = tf.reduce_mean(elements)\n",
    "        return loss"
   ],
   "id": "f787b1bfb478bb2c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.678264Z",
     "start_time": "2024-04-24T23:15:14.664301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ],
   "id": "f95117ea9219c326",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.694251Z",
     "start_time": "2024-04-24T23:15:14.680256Z"
    }
   },
   "cell_type": "code",
   "source": "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()",
   "id": "4c8a181e94619efb",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.710209Z",
     "start_time": "2024-04-24T23:15:14.695242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @tf.function\n",
    "# def train_step(images, labels):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         logits = model(images, training=True)\n",
    "#         loss = loss_fn(labels, logits)\n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "#     accuracy = accuracy_metric(labels, logits)\n",
    "#     return loss, accuracy"
   ],
   "id": "f1afa4d56b916759",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.726134Z",
     "start_time": "2024-04-24T23:15:14.711203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @tf.function\n",
    "# def test_step(images, labels):\n",
    "#     logits = model(images, training=False)\n",
    "#     loss = loss_fn(labels, logits)\n",
    "#     accuracy = accuracy_metric(labels, logits)\n",
    "#     return loss, accuracy"
   ],
   "id": "745856292f22b875",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.742091Z",
     "start_time": "2024-04-24T23:15:14.727131Z"
    }
   },
   "cell_type": "code",
   "source": "num_epochs = 20",
   "id": "449cde9979e5efcb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.758054Z",
     "start_time": "2024-04-24T23:15:14.743089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "#     accuracy_metric.reset_state()\n",
    "# \n",
    "#     for images, labels in train_dataset:\n",
    "#         loss, accuracy = train_step(images, labels)\n",
    "#         accuracy_metric.update_state(accuracy, labels)\n",
    "#         print('Loss: {}, Accuracy: {}'.format(loss, accuracy))\n",
    "# \n",
    "#     print(f\"Epoch accuracy: {accuracy_metric.result().numpy()}\")\n",
    "# \n",
    "#     accuracy_metric.reset_state()\n",
    "#     for images, labels in test_dataset:\n",
    "#         loss, accuracy = test_step(images, labels)\n",
    "#         accuracy_metric.update_state(accuracy, labels)\n",
    "#         print('Loss: {}, Accuracy: {}'.format(loss, accuracy))\n",
    "# \n",
    "#     print(f\"Epoch accuracy: {accuracy_metric.result().numpy()}\")"
   ],
   "id": "926ae59d03e55a06",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.880719Z",
     "start_time": "2024-04-24T23:15:14.759046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=[accuracy_metric])\n",
    "model.build(input_shape = (None, 32, 32, 3))\n",
    "model.summary()"
   ],
   "id": "d7be05417ed18184",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ up_sampling2d (\u001B[38;5;33mUpSampling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m3\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001B[38;5;33mUpSampling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m128\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_2 (\u001B[38;5;33mUpSampling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m3\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (\u001B[38;5;33mFunctional\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │    \u001B[38;5;34m21,802,784\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_94          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │         \u001B[38;5;34m8,192\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │       \u001B[38;5;34m131,136\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_95          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_96          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │           \u001B[38;5;34m495\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_94          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_95          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_96          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,945,071\u001B[0m (83.71 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,945,071</span> (83.71 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m21,906,351\u001B[0m (83.57 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,906,351</span> (83.57 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m38,720\u001B[0m (151.25 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,720</span> (151.25 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.896676Z",
     "start_time": "2024-04-24T23:15:14.882714Z"
    }
   },
   "cell_type": "code",
   "source": "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=1e-4)",
   "id": "70a76794ccfe9fa9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T23:15:14.912634Z",
     "start_time": "2024-04-24T23:15:14.898672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'supplementary.csv'\n",
    "csv_logger = CSVLogger(filename)"
   ],
   "id": "c7e1ed9d23c3e807",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T05:19:36.521375Z",
     "start_time": "2024-04-24T23:15:14.914629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=64, \n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[reduce_lr, csv_logger],\n",
    "    verbose = 1\n",
    ")"
   ],
   "id": "1808f9f1d2c433ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1192s\u001B[0m 8s/step - accuracy: 0.0706 - loss: 5.8221 - val_accuracy: 0.0635 - val_loss: 5.8209 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1122s\u001B[0m 8s/step - accuracy: 0.0797 - loss: 5.8214 - val_accuracy: 0.1021 - val_loss: 5.8209 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1093s\u001B[0m 8s/step - accuracy: 0.0885 - loss: 5.8211 - val_accuracy: 0.1231 - val_loss: 5.8208 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1094s\u001B[0m 8s/step - accuracy: 0.1006 - loss: 5.8210 - val_accuracy: 0.1457 - val_loss: 5.8210 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1087s\u001B[0m 8s/step - accuracy: 0.1286 - loss: 5.8209 - val_accuracy: 0.1924 - val_loss: 5.8208 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.1562 - loss: 5.8208 - val_accuracy: 0.1971 - val_loss: 5.8207 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1082s\u001B[0m 8s/step - accuracy: 0.1618 - loss: 5.8207 - val_accuracy: 0.2559 - val_loss: 5.8206 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1084s\u001B[0m 8s/step - accuracy: 0.2011 - loss: 5.8206 - val_accuracy: 0.2890 - val_loss: 5.8205 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.2385 - loss: 5.8205 - val_accuracy: 0.2423 - val_loss: 5.8205 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1083s\u001B[0m 8s/step - accuracy: 0.2678 - loss: 5.8204 - val_accuracy: 0.3438 - val_loss: 5.8204 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.3136 - loss: 5.8203 - val_accuracy: 0.3444 - val_loss: 5.8203 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1084s\u001B[0m 8s/step - accuracy: 0.3525 - loss: 5.8202 - val_accuracy: 0.4362 - val_loss: 5.8201 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1084s\u001B[0m 8s/step - accuracy: 0.3635 - loss: 5.8202 - val_accuracy: 0.3827 - val_loss: 5.8201 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1084s\u001B[0m 8s/step - accuracy: 0.4120 - loss: 5.8200 - val_accuracy: 0.4942 - val_loss: 5.8198 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.4512 - loss: 5.8199 - val_accuracy: 0.1706 - val_loss: 5.8207 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.3985 - loss: 5.8201 - val_accuracy: 0.2331 - val_loss: 5.8207 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1084s\u001B[0m 8s/step - accuracy: 0.3807 - loss: 5.8202 - val_accuracy: 0.4596 - val_loss: 5.8199 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1086s\u001B[0m 8s/step - accuracy: 0.4950 - loss: 5.8198 - val_accuracy: 0.5591 - val_loss: 5.8196 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1085s\u001B[0m 8s/step - accuracy: 0.5334 - loss: 5.8197 - val_accuracy: 0.6297 - val_loss: 5.8194 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1085s\u001B[0m 8s/step - accuracy: 0.5535 - loss: 5.8196 - val_accuracy: 0.5903 - val_loss: 5.8195 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:27:24.896164Z",
     "start_time": "2024-04-25T10:25:30.827457Z"
    }
   },
   "cell_type": "code",
   "source": "loss, acc = model.evaluate(test_dataset, verbose=0)",
   "id": "c6b93e7ee33ebc20",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:29:28.506815Z",
     "start_time": "2024-04-25T10:29:28.491823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loss = history.history['loss'][-1]\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "test_loss = history.history['val_loss'][-1]\n",
    "test_accuracy = history.history['val_accuracy'][-1]\n",
    "print(f\"Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
   ],
   "id": "b390ca28d1faa861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.8196, Train accuracy: 0.5467\n",
      "Test loss: 5.8195, Test accuracy: 0.5903\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# model.save('inception_ngl.keras')",
   "id": "a4025f12bfca778c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:30:11.350154Z",
     "start_time": "2024-04-25T10:30:11.330207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "image_labels = ['country line dancing',\n",
    " 'tango dancing',\n",
    " 'swing dancing',\n",
    " 'jumpstyle dancing',\n",
    " 'dancing gangnam style',\n",
    " 'square dancing',\n",
    " 'dancing charleston',\n",
    " 'salsa dancing',\n",
    " 'mosh pit dancing',\n",
    " 'robot dancing',\n",
    " 'tap dancing',\n",
    " 'breakdancing',\n",
    " 'belly dancing',\n",
    " 'dancing ballet',\n",
    " 'dancing macarena']\n"
   ],
   "id": "f801f2a33570d974",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:39:54.334875Z",
     "start_time": "2024-04-25T10:38:27.851323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_video(video):\n",
    "    classes = []\n",
    "    prob = []\n",
    "    image_names = test_df.loc[test_df['video'] == video, 'frame_path']\n",
    "    for image_name in image_names:\n",
    "        image = tf.io.read_file(image_name)\n",
    "        image = tf.image.decode_jpeg(image, channels = 3)\n",
    "        image = tf.image.resize(image, [32,32])\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image / 225\n",
    "        pred = model.predict(image)\n",
    "        predicted_label_index = np.argmax(pred[0])\n",
    "        probability = pred[0][predicted_label_index]\n",
    "        # print(f\"Предсказанный класс: {image_labels[predicted_label_index]}, Вероятность: {probability:.4f}\")\n",
    "        classes.append(image_labels[predicted_label_index])\n",
    "        prob.append(probability)\n",
    "    dict = pd.DataFrame({'label': classes, 'probability': prob})\n",
    "    max_dict_prob = dict.mode()['probability'].max()\n",
    "    pdict = dict[dict['label'] == f\"{dict.mode()['label'][0]}\"]\n",
    "    return max_dict_prob, pdict"
   ],
   "id": "d95a2d43a4c30f77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1347\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1346\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1305\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1299\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1287\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1239\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1222\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1266\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1321\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1496\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1538\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1634\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1427\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1411\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1244\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1311\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1321\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1314\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1406\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1236\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4s/step\n",
      "Предсказанный класс: tango dancing, Вероятность: 0.1232\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "videos = test_df['video']\n",
    "for video in videos:\n",
    "    max_dict_prob, pdict = predict_video(video)\n",
    "    print(f\"Класс видео: {test_df.loc[test_df['video'] == video, 'label'].values[0]}\")\n",
    "    print(\"_______________________________________\")\n",
    "    print(f\"Наиболее встречающийся класс: {dict.mode()['label'][0]} , средняя вероятность {pdict['probability'].mean()}\")\n",
    "    print(f\"Наибольшая вероятность: {max_dict_prob}, класс {dict.loc[dict['probability'] == max_dict_prob, 'label'].values[0]}\")"
   ],
   "id": "7e49ad142cbcb031"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:39:54.350839Z",
     "start_time": "2024-04-25T10:39:54.336870Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "238d773f69afda33",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T10:39:54.366791Z",
     "start_time": "2024-04-25T10:39:54.351830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(f\"Класс видео: {frames_df.loc[frames_df['video'] == video, 'label'].values[0]}\")\n",
    "# print(\"_______________________________________\")\n",
    "# print(\"Предсказанные классы по фреймам:\")\n",
    "# print(dict)\n",
    "# print(f\"Наиболее встречающийся класс: {dict.mode()['label'][0]} , средняя вероятность {pdict['probability'].mean()}\")\n",
    "# print(f\"Наибольшая вероятность: {max_dict_prob}, класс {dict.loc[dict['probability'] == max_dict_prob, 'label'].values[0]}\")"
   ],
   "id": "1b7d4c20ccc7a9a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс видео: tango dancing\n",
      "_______________________________________\n",
      "Предсказанные классы по фреймам:\n",
      "            label  probability\n",
      "0   tango dancing     0.134746\n",
      "1   tango dancing     0.134590\n",
      "2   tango dancing     0.130474\n",
      "3   tango dancing     0.129858\n",
      "4   tango dancing     0.128675\n",
      "5   tango dancing     0.123899\n",
      "6   tango dancing     0.122184\n",
      "7   tango dancing     0.126576\n",
      "8   tango dancing     0.132133\n",
      "9   tango dancing     0.149597\n",
      "10  tango dancing     0.153763\n",
      "11  tango dancing     0.163447\n",
      "12  tango dancing     0.142676\n",
      "13  tango dancing     0.141084\n",
      "14  tango dancing     0.124360\n",
      "15  tango dancing     0.131107\n",
      "16  tango dancing     0.132135\n",
      "17  tango dancing     0.131415\n",
      "18  tango dancing     0.140565\n",
      "19  tango dancing     0.123596\n",
      "20  tango dancing     0.123248\n",
      "Наиболее встречающийся класс: tango dancing , средняя вероятность 0.1342919021844864\n",
      "Наибольшая вероятность: 0.16344745457172394, класс tango dancing\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Видео: x0LzgIUDIes\n",
    "Модель на 20 кадров в видео\n",
    "Класс видео: mosh pit dancing\n",
    "_______________________________________\n",
    "Предсказанные классы по фреймам:\n",
    "                label  probability\n",
    "0   jumpstyle dancing     0.153224\n",
    "1   jumpstyle dancing     0.146594\n",
    "2   jumpstyle dancing     0.151000\n",
    "3   jumpstyle dancing     0.141237\n",
    "4   jumpstyle dancing     0.131609\n",
    "5   jumpstyle dancing     0.169623\n",
    "6   jumpstyle dancing     0.172320\n",
    "7   jumpstyle dancing     0.180115\n",
    "8       belly dancing     0.124170\n",
    "9    dancing macarena     0.122473\n",
    "10   dancing macarena     0.161632\n",
    "11   dancing macarena     0.131638\n",
    "12      belly dancing     0.123214\n",
    "13   mosh pit dancing     0.214120\n",
    "14   mosh pit dancing     0.205695\n",
    "15   mosh pit dancing     0.295078\n",
    "16     square dancing     0.211966\n",
    "17   mosh pit dancing     0.280752\n",
    "18   mosh pit dancing     0.335356\n",
    "19   mosh pit dancing     0.221957\n",
    "20   mosh pit dancing     0.236604\n",
    "Наиболее встречающийся класс: jumpstyle dancing , средняя вероятность 0.15571531653404236\n",
    "Наибольшая вероятность: 0.33535560965538025, класс mosh pit dancing"
   ],
   "id": "5152381e048d689f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO: добавить метрики для видео, подача 100 видео, разделение test/train поменять",
   "id": "db022ca37525fd92"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
